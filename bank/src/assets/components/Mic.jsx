import React, { useEffect, useRef, useState } from "react";

export default function Mic() {
  const [isRecording, setIsRecording] = useState(false);
  const recognitionRef = useRef(null);
  const transcriptRef = useRef("");
  const btnRef = useRef();

  useEffect(() => {
    if (!("webkitSpeechRecognition" in window) && !("SpeechRecognition" in window)) {
      alert("ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      if (btnRef.current) btnRef.current.disabled = true;
      return;
    }
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    recognition.lang = "ko-KR";
    recognition.interimResults = false;
    recognition.continuous = false;

    recognition.onstart = () => {
      transcriptRef.current = "";
      setIsRecording(true);
    };
    recognition.onresult = (event) => {
      for (let i = event.resultIndex; i < event.results.length; ++i) {
        transcriptRef.current += event.results[i][0].transcript;
      }
    };
    recognition.onerror = () => setIsRecording(false);
    recognition.onend = () => {
      setIsRecording(false);
      const userSpeech = transcriptRef.current.trim();
      if (!userSpeech) return;
      window.speechSynthesis.cancel();
      fetch("http://localhost:3000/askgpt", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ question: userSpeech }),
      })
        .then((r) => r.json())
        .then((data) => {
          let answer = data.answer || "ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.";
          const moveMatch = answer.match(/í˜ì´ì§€ ì´ë™: (home\.html|benefit\.html|pay\.html|money\.html|paper\.html)/);
          if (moveMatch) {
            window.location.href = moveMatch[1];
          } else {
            const tts = new window.SpeechSynthesisUtterance(answer);
            tts.lang = "ko-KR";
            window.speechSynthesis.speak(tts);
          }
        });
    };

    recognitionRef.current = recognition;

    return () => {
      recognition.stop();
      recognitionRef.current = null;
    };
  }, []);

  const onMicClick = () => {
    window.speechSynthesis.cancel();
    if (!isRecording) {
      recognitionRef.current && recognitionRef.current.start();
    } else {
      recognitionRef.current && recognitionRef.current.stop();
    }
  };

  return (
    <button
      ref={btnRef}
      className="fixed left-1/2 bottom-12 -translate-x-1/2 z-30 w-64 h-16 bg-gray-100 rounded-full shadow-lg flex items-center justify-center border-none transition text-[2.4rem] active:scale-95"
      id="voice-btn"
      title="ìŒì„± ì§ˆë¬¸"
      onClick={onMicClick}
    >
      <span className="text-4xl">ğŸ™ï¸</span>
    </button>
  );
}
